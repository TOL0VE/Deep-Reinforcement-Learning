import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.tensorboard import SummaryWriter
import time

# === 0. è‡ªåŠ¨æ£€æµ‹ GPU è®¾å¤‡ ===
# å¦‚æœæœ‰ NVIDIA æ˜¾å¡ä¸”å®‰è£…äº† CUDAï¼Œå°±ä½¿ç”¨ 'cuda'ï¼Œå¦åˆ™ä½¿ç”¨ 'cpu'
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"ğŸš€ å½“å‰ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡: {device}")
if device.type == 'cuda':
    print(f"   æ˜¾å¡å‹å·: {torch.cuda.get_device_name(0)}")
else:
    print("   âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œæ­£åœ¨ä½¿ç”¨ CPU æ…¢é€Ÿè¿è¡Œ...")

# === A. åˆå§‹åŒ–å¯è§†åŒ–å·¥å…· ===
writer = SummaryWriter('runs/amp_gpu_experiment')

# === B. æ•°æ®æº (éœ€è¦æ¬è¿åˆ° device) ===
def get_good_motion(batch_size):
    """ çœŸå®æ•°æ® (TOWR): åœ†å‘¨è¿åŠ¨ """
    t = torch.rand(batch_size, 1) * 2 * np.pi #batch_size x 1
    data = torch.cat([torch.sin(t), torch.cos(t)], dim=1)# batch_size x 2
    # ã€å…³é”®ã€‘æŠŠæ•°æ®æ¬åˆ° GPU
    return data.to(device)

def get_bad_motion(batch_size):
    """ å‡æ•°æ® (RLåˆæœŸ): é«˜æ–¯å™ªå£° """
    data = torch.randn(batch_size, 2)# batch_size x 2
    # ã€å…³é”®ã€‘æŠŠæ•°æ®æ¬åˆ° GPU
    return data.to(device)

# === C. åˆ¤åˆ«å™¨ (éœ€è¦æ¬è¿åˆ° device) ===
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 64), # åŠ å¤§ä¸€ç‚¹ç½‘ç»œçœ‹çœ‹ GPU å¨åŠ›
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.net(x)

# === D. è®­ç»ƒå¾ªç¯ ===
def run_experiment():
    # 1. å®ä¾‹åŒ–ç½‘ç»œ
    D = Discriminator()
    
    # ã€å…³é”®ã€‘æŠŠæ•´ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹æ¬åˆ° GPU
    D = D.to(device)
    
    optimizer = optim.Adam(D.parameters(), lr=0.001)
    '''D.parameters(): è¿™å°±æ˜¯å…¬å¼é‡Œçš„ $\theta$ï¼ˆæˆ‘ä»¬éœ€è¦ä¼˜åŒ–çš„å˜é‡ï¼šæƒé‡ $W$ å’Œåç½® $b$ï¼‰ã€‚
    lr=0.001: è¿™å°±æ˜¯åŸºç¡€æ­¥é•¿ $\alpha$ã€‚
    æ¯”åˆšå¼€å§‹å­¦çš„SGDä¼˜åŒ–å™¨æ›´é«˜çº§ï¼Œä½†æœ¬è´¨æ˜¯ä¸€æ ·çš„ã€‚
    '''

    loss_fn = nn.BCELoss()

    print("å¼€å§‹æé€Ÿè®­ç»ƒ...")
    start_time = time.time()

    # å¢åŠ è®­ç»ƒæ­¥æ•°ï¼Œä½“ç° GPU ä¼˜åŠ¿
    total_steps = 100000
    
    for step in range(total_steps):
        # 1. å‡†å¤‡æ•°æ® (å·²ç»åœ¨ get_motion å‡½æ•°é‡Œ to(device) äº†)
        real_data = get_good_motion(1024) # åŠ å¤§ Batch Size æ¦¨å¹²æ˜¾å¡
        fake_data = get_bad_motion(1024)

        # 2. å‰å‘ä¼ æ’­
        pred_real = D(real_data)
        pred_fake = D(fake_data)

        # 3. è®¡ç®— Loss
        loss_real = loss_fn(pred_real, torch.ones_like(pred_real))
        loss_fake = loss_fn(pred_fake, torch.zeros_like(pred_fake))
        total_loss = loss_real + loss_fake

        # 4. åå‘ä¼ æ’­
        optimizer.zero_grad()
        '''å­—é¢æ„æ€ï¼šæŠŠæ¢¯åº¦çš„ç§¯ç´¯æ¸…é›¶ã€‚
        ä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼Ÿ
        åœ¨ PyTorch çš„è®¾è®¡ä¸­ï¼Œ.grad æ˜¯ç´¯åŠ çš„ï¼ˆAccumulatedï¼‰ã€‚
        å¦‚æœä½ ä¸åŠ è¿™è¡Œï¼Œç¬¬ 1 æ­¥ç®—å‡ºçš„æ¢¯åº¦æ˜¯ $g_1$ã€‚
        ç¬¬ 2 æ­¥ç®—å‡ºçš„æ¢¯åº¦æ˜¯ $g_2$ï¼ŒPyTorch ä¼šæŠŠå®ƒåŠ åˆ°åŸæ¥çš„ä¸Šé¢ï¼Œå˜æˆ $g_1 + g_2$ã€‚
        ç¬¬ 3 æ­¥å˜æˆ $g_1 + g_2 + g_3$ã€‚
        è¿™åœ¨ RNN è¿™ç§ç‰¹æ®Šç½‘ç»œé‡Œæœ‰ç”¨ï¼Œä½†åœ¨æˆ‘ä»¬è¿™é‡Œæ˜¯å¤§å¿Œï¼æˆ‘ä»¬å¸Œæœ›æ¯ä¸€æ­¥çš„æ¢¯åº¦åªä»£è¡¨å½“ä¸‹çš„æ–¹å‘ã€‚
        
        ç±»æ¯”ï¼šè¿™å°±å¥½æ¯”ä½ è¦ç§°é‡ã€‚æ¯æ¬¡ç§°é‡å‰ï¼Œéƒ½è¦æŠŠç§¤å½’é›¶ï¼Œå¦åˆ™ä¸‹ä¸€æ¬¡ç§°çš„å°±æ˜¯ä¸¤ä¸ªç‰©ä½“çš„æ€»é‡äº†ã€‚'''
        total_loss.backward()# è®¡ç®—æ–°çš„æ¢¯åº¦
        optimizer.step()# theta t+1 = ********

        # === E. åŸ‹ç‚¹è®°å½• ===
        # æ³¨æ„ï¼šå†™å…¥ TensorBoard æ—¶ï¼Œé€šå¸¸éœ€è¦æŠŠæ•°æ®ä» GPU æ‹‰å› CPU (.item() ä¼šè‡ªåŠ¨å¤„ç†ï¼Œä½†å¦‚æœæ˜¯ tensor å°±è¦ .cpu())
        if step % 100 == 0:
            # è®°å½•åˆ° TensorBoard
            writer.add_scalar('Loss/Total', total_loss.item(), step)
            writer.add_scalar('Score/Real_Prob', pred_real.mean().item(), step)
            writer.add_scalar('Score/Fake_Prob', pred_fake.mean().item(), step)
            
            print(f"Step {step}: Loss = {total_loss.item():.4f}")

    end_time = time.time()
    duration = end_time - start_time
    print("-" * 50)
    print(f"âœ… è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“Š æ€»è€—æ—¶: {duration:.2f} ç§’")
    print(f"ğŸš€ å¹³å‡é€Ÿåº¦: {total_steps / duration:.1f} steps/sec")
    print("-" * 50)
    
    writer.close()

if __name__ == "__main__":
    run_experiment()